{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589921b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Vaibha3246\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Vaibha3246\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Vaibha3246/influence_mirror\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Vaibha3246/influence_mirror\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Vaibha3246/influence_mirror initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Vaibha3246/influence_mirror initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='Vaibha3246', repo_name='influence_mirror', mlflow=True)\n",
    "\n",
    "import mlflow\n",
    "# Step 2: Set up the MLflow tracking server\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Vaibha3246/influence_mirror.mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2e2b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/adb82bab710d416190b0fea77cabca06', creation_time=1760159677050, experiment_id='3', last_update_time=1760159677050, lifecycle_stage='active', name='exp_5 ml_algo_with_hp_tunning', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set or create an experiment\n",
    "mlflow.set_experiment(\"exp_5 ml_algo_with_hp_tunning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e690dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('preprocessing.csv').dropna(subset=['text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7298469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:05:13,746] A new study created in memory with name: no-name-f788bbc3-b8ad-4d13-b47d-ffb7f0b0f569\n",
      "[I 2025-10-24 12:05:14,265] Trial 0 finished with value: 0.6635349144667767 and parameters: {'alpha': 0.060707414027673295, 'fit_prior': True}. Best is trial 0 with value: 0.6635349144667767.\n",
      "[I 2025-10-24 12:05:14,277] Trial 1 finished with value: 0.644001019363842 and parameters: {'alpha': 0.0010238917491002817, 'fit_prior': False}. Best is trial 0 with value: 0.6635349144667767.\n",
      "[I 2025-10-24 12:05:14,291] Trial 2 finished with value: 0.656969071691214 and parameters: {'alpha': 0.0036520975067028524, 'fit_prior': True}. Best is trial 0 with value: 0.6635349144667767.\n",
      "[I 2025-10-24 12:05:14,308] Trial 3 finished with value: 0.6696268690463592 and parameters: {'alpha': 0.05063857017983732, 'fit_prior': True}. Best is trial 3 with value: 0.6696268690463592.\n",
      "[I 2025-10-24 12:05:14,325] Trial 4 finished with value: 0.644045356101064 and parameters: {'alpha': 0.0010520338037257868, 'fit_prior': False}. Best is trial 3 with value: 0.6696268690463592.\n",
      "[I 2025-10-24 12:05:14,348] Trial 5 finished with value: 0.6521257849530927 and parameters: {'alpha': 0.005837615528984576, 'fit_prior': False}. Best is trial 3 with value: 0.6696268690463592.\n",
      "[I 2025-10-24 12:05:14,365] Trial 6 finished with value: 0.651413257023566 and parameters: {'alpha': 0.02042059397551949, 'fit_prior': True}. Best is trial 3 with value: 0.6696268690463592.\n",
      "[I 2025-10-24 12:05:14,382] Trial 7 finished with value: 0.6823088187507144 and parameters: {'alpha': 1.3198945544252123, 'fit_prior': True}. Best is trial 7 with value: 0.6823088187507144.\n",
      "[I 2025-10-24 12:05:14,397] Trial 8 finished with value: 0.6719582793512309 and parameters: {'alpha': 1.231078763151584, 'fit_prior': True}. Best is trial 7 with value: 0.6823088187507144.\n",
      "[I 2025-10-24 12:05:14,416] Trial 9 finished with value: 0.678217635059126 and parameters: {'alpha': 0.296439609353081, 'fit_prior': False}. Best is trial 7 with value: 0.6823088187507144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run NaiveBayes_TFIDF_SMOTE_Optuna_Fast at: https://dagshub.com/Vaibha3246/influence_mirror.mlflow/#/experiments/3/runs/3eff6eecfbb04025a12e710ffc1650c5\n",
      "üß™ View experiment at: https://dagshub.com/Vaibha3246/influence_mirror.mlflow/#/experiments/3\n",
      " MLflow run logged successfully for Naive Bayes (TF-IDF + SMOTE + Optuna)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "#  Optimized Naive Bayes (Optuna + SMOTE + MLflow)\n",
    "# -----------------------------\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import scipy.sparse as sp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Clean target\n",
    "# -----------------------------\n",
    "df['sentiment_numeric'] = df['sentiment_numeric'].map({-1: 2, 0: 0, 1: 1})\n",
    "df = df.dropna(subset=['sentiment_numeric'])\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Select features\n",
    "# -----------------------------\n",
    "numeric_cols = [col for col in df.columns if col not in [\n",
    "    'video_id', 'category', 'text', 'text_clean', 'sentiment',\n",
    "    'dominant_emotion', 'published_at', 'sentiment_numeric'\n",
    "]]\n",
    "\n",
    "X = df[numeric_cols]\n",
    "y = df['sentiment_numeric']\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Train/Test Split\n",
    "# -----------------------------\n",
    "X_train_raw, X_test_raw, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "    X, y, df.index, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Scale numeric features (0‚Äì1 range for NB)\n",
    "# -----------------------------\n",
    "scaler = MinMaxScaler()\n",
    "X_train_num = scaler.fit_transform(X_train_raw)\n",
    "X_test_num = scaler.transform(X_test_raw)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 5: TF-IDF for text\n",
    "# -----------------------------\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=7000)\n",
    "X_train_text = tfidf.fit_transform(df.loc[train_idx, 'text_clean'])\n",
    "X_test_text = tfidf.transform(df.loc[test_idx, 'text_clean'])\n",
    "\n",
    "# Combine numeric + text\n",
    "X_train = sp.hstack([X_train_text, sp.csr_matrix(X_train_num)])\n",
    "X_test = sp.hstack([X_test_text, sp.csr_matrix(X_test_num)])\n",
    "\n",
    "# -----------------------------\n",
    "# Step 6: Apply SMOTE\n",
    "# -----------------------------\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 7: Optuna Objective (subset for tuning)\n",
    "# -----------------------------\n",
    "def objective(trial):\n",
    "    sample_size = min(2000, X_train_res.shape[0])\n",
    "    idx = np.random.choice(X_train_res.shape[0], sample_size, replace=False)\n",
    "    \n",
    "    X_sample = X_train_res[idx]\n",
    "    y_sample = np.array(y_train_res)[idx]\n",
    "\n",
    "    params = {\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.001, 2.0, log=True),\n",
    "        \"fit_prior\": trial.suggest_categorical(\"fit_prior\", [True, False])\n",
    "    }\n",
    "\n",
    "    model = MultinomialNB(**params)\n",
    "    model.fit(X_sample, y_sample)\n",
    "    preds = model.predict(X_test)\n",
    "    return f1_score(y_test, preds, average=\"macro\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 8: Run Optuna Tuning\n",
    "# -----------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 9: Train Full Best Model\n",
    "# -----------------------------\n",
    "best_params = study.best_params\n",
    "best_model = MultinomialNB(**best_params)\n",
    "best_model.fit(X_train_res, y_train_res)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 10: MLflow Logging\n",
    "# -----------------------------\n",
    "with mlflow.start_run(run_name=\"NaiveBayes_TFIDF_SMOTE_Optuna_Fast\"):\n",
    "    mlflow.log_param(\"algorithm\", \"MultinomialNB\")\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_param(\"vectorizer_type\", \"TF-IDF\")\n",
    "    mlflow.log_param(\"ngram_range\", \"(1,2)\")\n",
    "    mlflow.log_param(\"max_features\", 7000)\n",
    "    mlflow.log_param(\"imbalance_method\", \"SMOTE\")\n",
    "\n",
    "    # Metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "    mlflow.log_metric(\"f1_macro\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "\n",
    "    # Detailed report\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    for label, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            for metric, val in metrics.items():\n",
    "                mlflow.log_metric(f\"{label}_{metric}\", val)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix: Naive Bayes Best Model\")\n",
    "    plt.savefig(\"confusion_matrix_naivebayes.png\")\n",
    "    mlflow.log_artifact(\"confusion_matrix_naivebayes.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Save model & preprocessors\n",
    "    joblib.dump(best_model, \"naivebayes_best_model.pkl\")\n",
    "    joblib.dump(scaler, \"scaler.pkl\")\n",
    "    joblib.dump(tfidf, \"tfidf_vectorizer.pkl\")\n",
    "    mlflow.log_artifact(\"naivebayes_best_model.pkl\")\n",
    "    mlflow.log_artifact(\"scaler.pkl\")\n",
    "    mlflow.log_artifact(\"tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\" MLflow run logged successfully for Naive Bayes (TF-IDF + SMOTE + Optuna)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b9d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
