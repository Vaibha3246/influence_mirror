{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0070cd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: xgboost in e:\\influence-mirror\\myenv\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: imbalanced-learn in e:\\influence-mirror\\myenv\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from optuna) (1.16.5)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in e:\\influence-mirror\\myenv\\lib\\site-packages (from optuna) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in e:\\influence-mirror\\myenv\\lib\\site-packages (from optuna) (2.0.43)\n",
      "Requirement already satisfied: tqdm in e:\\influence-mirror\\myenv\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in e:\\influence-mirror\\myenv\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: scipy in e:\\influence-mirror\\myenv\\lib\\site-packages (from xgboost) (1.16.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in e:\\influence-mirror\\myenv\\lib\\site-packages (from imbalanced-learn) (1.7.2)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Requirement already satisfied: Mako in e:\\influence-mirror\\myenv\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in e:\\influence-mirror\\myenv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
      "Requirement already satisfied: colorama in e:\\influence-mirror\\myenv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in e:\\influence-mirror\\myenv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: colorlog, optuna\n",
      "Successfully installed colorlog-6.9.0 optuna-4.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install  optuna xgboost imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d15b928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Vaibha3246\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Vaibha3246\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Vaibha3246/influence_mirror\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Vaibha3246/influence_mirror\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Vaibha3246/influence_mirror initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Vaibha3246/influence_mirror initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='Vaibha3246', repo_name='influence_mirror', mlflow=True)\n",
    "\n",
    "import mlflow\n",
    "# Step 2: Set up the MLflow tracking server\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Vaibha3246/influence_mirror.mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebfa66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7160a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d024c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/11 10:44:38 INFO mlflow.tracking.fluent: Experiment with name 'exp_5 ml_algo_with_hp_tunning' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/adb82bab710d416190b0fea77cabca06', creation_time=1760159677050, experiment_id='3', last_update_time=1760159677050, lifecycle_stage='active', name='exp_5 ml_algo_with_hp_tunning', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set or create an experiment\n",
    "mlflow.set_experiment(\"exp_5 ml_algo_with_hp_tunning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea280d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\influence-mirror\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4806adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d882a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9e7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('preprocessing.csv').dropna(subset=['text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e031862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 21:03:43,400] A new study created in memory with name: no-name-254d6a6f-1c96-46b5-ad0f-0bdddd44a393\n",
      "[I 2025-10-11 21:05:12,075] Trial 0 finished with value: 0.7661758143685855 and parameters: {'n_estimators': 315, 'max_depth': 8, 'learning_rate': 0.03745891237904555, 'subsample': 0.869164239375805, 'colsample_bytree': 0.6906325659196921, 'gamma': 0.8795923404622225, 'min_child_weight': 10, 'reg_alpha': 0.08164439998607109, 'reg_lambda': 1.117189284477916}. Best is trial 0 with value: 0.7661758143685855.\n",
      "[I 2025-10-11 21:05:45,067] Trial 1 finished with value: 0.7714190093708166 and parameters: {'n_estimators': 339, 'max_depth': 4, 'learning_rate': 0.1407850936758751, 'subsample': 0.9486371399409629, 'colsample_bytree': 0.8451784557246457, 'gamma': 2.64009369294226, 'min_child_weight': 8, 'reg_alpha': 0.9367292715293631, 'reg_lambda': 1.7362511250058374}. Best is trial 1 with value: 0.7714190093708166.\n",
      "[I 2025-10-11 21:06:44,395] Trial 2 finished with value: 0.7542391789379741 and parameters: {'n_estimators': 173, 'max_depth': 9, 'learning_rate': 0.030688024151702967, 'subsample': 0.768480297337809, 'colsample_bytree': 0.8099260478653192, 'gamma': 4.444737868142006, 'min_child_weight': 3, 'reg_alpha': 0.3253064950575443, 'reg_lambda': 1.308786119764504}. Best is trial 1 with value: 0.7714190093708166.\n",
      "[I 2025-10-11 21:07:30,087] Trial 3 finished with value: 0.7745426149040607 and parameters: {'n_estimators': 148, 'max_depth': 11, 'learning_rate': 0.24940864803232402, 'subsample': 0.8520124803661074, 'colsample_bytree': 0.6517125789967164, 'gamma': 0.49027410866561705, 'min_child_weight': 10, 'reg_alpha': 0.029893353979546844, 'reg_lambda': 1.7806720382416978}. Best is trial 3 with value: 0.7745426149040607.\n",
      "[I 2025-10-11 21:08:00,434] Trial 4 finished with value: 0.6954484605087015 and parameters: {'n_estimators': 276, 'max_depth': 3, 'learning_rate': 0.013721096399840427, 'subsample': 0.8906743267806398, 'colsample_bytree': 0.9198251651239574, 'gamma': 1.0503124142374265, 'min_child_weight': 5, 'reg_alpha': 0.25535952452735844, 'reg_lambda': 0.7579739793533937}. Best is trial 3 with value: 0.7745426149040607.\n",
      "[I 2025-10-11 21:12:18,543] Trial 5 finished with value: 0.7772199910754127 and parameters: {'n_estimators': 386, 'max_depth': 15, 'learning_rate': 0.035199910657995166, 'subsample': 0.9933292028135163, 'colsample_bytree': 0.8262761713643547, 'gamma': 0.7097036343627122, 'min_child_weight': 6, 'reg_alpha': 0.63607153847418, 'reg_lambda': 0.5546409562560011}. Best is trial 5 with value: 0.7772199910754127.\n",
      "[I 2025-10-11 21:13:16,611] Trial 6 finished with value: 0.7807898259705489 and parameters: {'n_estimators': 110, 'max_depth': 11, 'learning_rate': 0.25398757755817536, 'subsample': 0.9655020024442897, 'colsample_bytree': 0.98646920617087, 'gamma': 0.580976874030596, 'min_child_weight': 2, 'reg_alpha': 0.3995273993402666, 'reg_lambda': 1.0253954644797911}. Best is trial 6 with value: 0.7807898259705489.\n",
      "[I 2025-10-11 21:14:43,827] Trial 7 finished with value: 0.7604863900044623 and parameters: {'n_estimators': 278, 'max_depth': 8, 'learning_rate': 0.026684511020360246, 'subsample': 0.8161408040170312, 'colsample_bytree': 0.9668359408825984, 'gamma': 3.14875470640021, 'min_child_weight': 6, 'reg_alpha': 0.849269830198474, 'reg_lambda': 1.4788092998494238}. Best is trial 6 with value: 0.7807898259705489.\n",
      "[I 2025-10-11 21:15:14,512] Trial 8 finished with value: 0.7446452476572959 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.039368289421625666, 'subsample': 0.6416264478242965, 'colsample_bytree': 0.6704822588013062, 'gamma': 1.2776269174250288, 'min_child_weight': 10, 'reg_alpha': 0.4543810726123808, 'reg_lambda': 0.7133368152992678}. Best is trial 6 with value: 0.7807898259705489.\n",
      "[I 2025-10-11 21:16:49,382] Trial 9 finished with value: 0.7705265506470326 and parameters: {'n_estimators': 353, 'max_depth': 9, 'learning_rate': 0.035437162080846595, 'subsample': 0.6915262458970559, 'colsample_bytree': 0.8192100263738964, 'gamma': 3.3393234572958304, 'min_child_weight': 8, 'reg_alpha': 0.17189061438985598, 'reg_lambda': 1.4769808678773324}. Best is trial 6 with value: 0.7807898259705489.\n",
      "[I 2025-10-11 21:18:35,179] Trial 10 finished with value: 0.783244087460955 and parameters: {'n_estimators': 209, 'max_depth': 13, 'learning_rate': 0.11151824933436703, 'subsample': 0.7375593622960934, 'colsample_bytree': 0.9893391739057276, 'gamma': 1.8570194304259569, 'min_child_weight': 1, 'reg_alpha': 0.6686045393859209, 'reg_lambda': 0.9872199177400731}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:20:45,405] Trial 11 finished with value: 0.7807898259705489 and parameters: {'n_estimators': 196, 'max_depth': 13, 'learning_rate': 0.10212112601038786, 'subsample': 0.7447377198609908, 'colsample_bytree': 0.9948905444052746, 'gamma': 1.780129755692601, 'min_child_weight': 1, 'reg_alpha': 0.6466551233294343, 'reg_lambda': 1.0023493295702697}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:21:35,001] Trial 12 finished with value: 0.7801204819277109 and parameters: {'n_estimators': 213, 'max_depth': 12, 'learning_rate': 0.29164746920397183, 'subsample': 0.7123324280415455, 'colsample_bytree': 0.9069218464005859, 'gamma': 1.9486465513560614, 'min_child_weight': 1, 'reg_alpha': 0.5654430919636059, 'reg_lambda': 0.9171267606881179}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:22:34,049] Trial 13 finished with value: 0.7748772869254797 and parameters: {'n_estimators': 103, 'max_depth': 14, 'learning_rate': 0.09082763959977799, 'subsample': 0.6167187453309396, 'colsample_bytree': 0.9145043116973001, 'gamma': 1.8199836553892543, 'min_child_weight': 3, 'reg_alpha': 0.7644826219421349, 'reg_lambda': 1.2397780997786838}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:24:05,613] Trial 14 finished with value: 0.7823516287371709 and parameters: {'n_estimators': 230, 'max_depth': 11, 'learning_rate': 0.16493584888267923, 'subsample': 0.9186150265920302, 'colsample_bytree': 0.7342107647640013, 'gamma': 0.19223996650784497, 'min_child_weight': 3, 'reg_alpha': 0.4525522699786893, 'reg_lambda': 0.890676158228742}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:25:36,853] Trial 15 finished with value: 0.7814591700133868 and parameters: {'n_estimators': 231, 'max_depth': 11, 'learning_rate': 0.14892487351424802, 'subsample': 0.9093300267590045, 'colsample_bytree': 0.7363258898834557, 'gamma': 0.029712054092279172, 'min_child_weight': 4, 'reg_alpha': 0.7513330584621385, 'reg_lambda': 0.8101665605856783}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:26:30,762] Trial 16 finished with value: 0.7753235162873717 and parameters: {'n_estimators': 264, 'max_depth': 15, 'learning_rate': 0.08590336474308823, 'subsample': 0.7981270145332995, 'colsample_bytree': 0.7601839611192827, 'gamma': 4.33164426127276, 'min_child_weight': 2, 'reg_alpha': 0.5081068899615838, 'reg_lambda': 0.5640039188224094}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:28:58,975] Trial 17 finished with value: 0.7813476126729139 and parameters: {'n_estimators': 235, 'max_depth': 13, 'learning_rate': 0.05905458456314668, 'subsample': 0.6760777602983138, 'colsample_bytree': 0.6156474153965069, 'gamma': 0.07738520688755214, 'min_child_weight': 4, 'reg_alpha': 0.980384697998081, 'reg_lambda': 1.1891577591037985}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:29:22,569] Trial 18 finished with value: 0.7662873717090585 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.1609724113412529, 'subsample': 0.8260862285909889, 'colsample_bytree': 0.7477154736809244, 'gamma': 4.996417463149808, 'min_child_weight': 2, 'reg_alpha': 0.3778838515306928, 'reg_lambda': 1.9526169994262512}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:31:20,700] Trial 19 finished with value: 0.7792280232039268 and parameters: {'n_estimators': 302, 'max_depth': 13, 'learning_rate': 0.06081753728366764, 'subsample': 0.75221711992784, 'colsample_bytree': 0.8714339710078275, 'gamma': 2.4034374417320556, 'min_child_weight': 1, 'reg_alpha': 0.6219423217538902, 'reg_lambda': 0.8956559881051721}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:31:49,875] Trial 20 finished with value: 0.7730923694779116 and parameters: {'n_estimators': 155, 'max_depth': 6, 'learning_rate': 0.17051731287269767, 'subsample': 0.9212365100734488, 'colsample_bytree': 0.771400444562872, 'gamma': 1.3757488186503166, 'min_child_weight': 3, 'reg_alpha': 0.7111073464907598, 'reg_lambda': 1.4102158964270526}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:33:17,417] Trial 21 finished with value: 0.7805667112896029 and parameters: {'n_estimators': 232, 'max_depth': 11, 'learning_rate': 0.12173879655669857, 'subsample': 0.9019441553472172, 'colsample_bytree': 0.7233998167756298, 'gamma': 0.30839514613056607, 'min_child_weight': 4, 'reg_alpha': 0.7944787091395681, 'reg_lambda': 0.7581206204445101}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:34:47,758] Trial 22 finished with value: 0.7810129406514948 and parameters: {'n_estimators': 216, 'max_depth': 12, 'learning_rate': 0.20113906872920048, 'subsample': 0.9267954871310057, 'colsample_bytree': 0.7135896428471354, 'gamma': 0.11023172004160571, 'min_child_weight': 4, 'reg_alpha': 0.857381651067385, 'reg_lambda': 0.8655052295372165}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:36:08,411] Trial 23 finished with value: 0.7747657295850067 and parameters: {'n_estimators': 246, 'max_depth': 10, 'learning_rate': 0.07348312387510081, 'subsample': 0.9934840523443109, 'colsample_bytree': 0.782319536114623, 'gamma': 1.4333670174571482, 'min_child_weight': 5, 'reg_alpha': 0.5261493669750065, 'reg_lambda': 0.6632663987940676}. Best is trial 10 with value: 0.783244087460955.\n",
      "[I 2025-10-11 21:38:13,341] Trial 24 finished with value: 0.7830209727800089 and parameters: {'n_estimators': 209, 'max_depth': 12, 'learning_rate': 0.12597363061014152, 'subsample': 0.846622452038309, 'colsample_bytree': 0.7295416531389496, 'gamma': 0.04175638363663224, 'min_child_weight': 2, 'reg_alpha': 0.6956655459696832, 'reg_lambda': 1.0442249788518152}. Best is trial 10 with value: 0.783244087460955.\n",
      "e:\\influence-mirror\\myenv\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [21:39:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/10/11 21:41:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run XGBoost_TFIDF_SMOTE_Optuna_Best at: https://dagshub.com/Vaibha3246/influence_mirror.mlflow/#/experiments/3/runs/36d2471a2b944f819278cf08c3c07413\n",
      "üß™ View experiment at: https://dagshub.com/Vaibha3246/influence_mirror.mlflow/#/experiments/3\n",
      "üéØ MLflow run logged successfully for XGBoost ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Step 1: Clean target\n",
    "# -------------------------\n",
    "df['sentiment_numeric'] = df['sentiment_numeric'].map({-1: 2, 0: 0, 1: 1})\n",
    "df = df.dropna(subset=['sentiment_numeric'])\n",
    "\n",
    "# -------------------------\n",
    "# Step 2: Select features\n",
    "# -------------------------\n",
    "numeric_cols = [col for col in df.columns if col not in [\n",
    "    'video_id', 'category', 'text', 'text_clean', 'sentiment',\n",
    "    'dominant_emotion', 'published_at', 'sentiment_numeric'\n",
    "]]\n",
    "\n",
    "X_numeric = df[numeric_cols]\n",
    "y = df['sentiment_numeric']\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_numeric_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "# Train/test split\n",
    "X_train_num, X_test_num, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "    X_numeric_scaled, y, df.index, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Step 3: TF-IDF for text\n",
    "# -------------------------\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,3), max_features=10000)\n",
    "X_train_text = tfidf.fit_transform(df.loc[train_idx, 'text_clean'])\n",
    "X_test_text = tfidf.transform(df.loc[test_idx, 'text_clean'])\n",
    "\n",
    "# Combine numeric + text\n",
    "X_train = sp.hstack([X_train_text, sp.csr_matrix(X_train_num)])\n",
    "X_test = sp.hstack([X_test_text, sp.csr_matrix(X_test_num)])\n",
    "\n",
    "# -------------------------\n",
    "# Step 4: Apply SMOTE\n",
    "# -------------------------\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Step 5: Define Optuna objective\n",
    "# -------------------------\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 400),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.5, 2.0),\n",
    "        \"objective\": \"multi:softmax\",       # <-- returns class labels directly\n",
    "        \"num_class\": len(np.unique(y)),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    return acc\n",
    "\n",
    "# -------------------------\n",
    "# Step 6: Run Optuna tuning\n",
    "# -------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "# -------------------------\n",
    "# Step 7: Train best XGBoost model\n",
    "# -------------------------\n",
    "best_params = study.best_params\n",
    "best_model = XGBClassifier(**best_params)\n",
    "best_model.fit(X_train_res, y_train_res)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# -------------------------\n",
    "# Step 8: Log metrics + model in MLflow\n",
    "# -------------------------\n",
    "with mlflow.start_run(run_name=\"XGBoost_TFIDF_SMOTE_Optuna_Best\"):\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_param(\"vectorizer_type\", \"TF-IDF\")\n",
    "    mlflow.log_param(\"ngram_range\", (1,3))\n",
    "    mlflow.log_param(\"max_features\", 10000)\n",
    "    mlflow.log_param(\"imbalance_method\", \"SMOTE\")\n",
    "\n",
    "    # Log accuracy\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # Log full classification report metrics\n",
    "    classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "    for label, metrics in classification_rep.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            for metric, value in metrics.items():\n",
    "                mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "    # Log confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix: XGBoost Best Model\")\n",
    "    plt.savefig(\"confusion_matrix_xgboost_best.png\")\n",
    "    mlflow.log_artifact(\"confusion_matrix_xgboost_best.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Log trained model\n",
    "    mlflow.xgboost.log_model(best_model, \"xgboost_best_model\")\n",
    "\n",
    "print(\"üéØ MLflow run logged successfully for XGBoost ‚úÖ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
