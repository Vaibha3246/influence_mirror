{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7ffaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in e:\\influence-mirror\\myenv\\lib\\site-packages (2.22.2)\n",
      "Requirement already satisfied: mlflow-skinny==2.22.2 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (2.22.2)\n",
      "Requirement already satisfied: Flask<4 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (3.1.6)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (1.16.5)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (3.9)\n",
      "Requirement already satisfied: matplotlib<4 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (3.10.6)\n",
      "Requirement already satisfied: numpy<3 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (2.3.3)\n",
      "Requirement already satisfied: pandas!=2.3.0,<3 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (2.3.2)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (19.0.1)\n",
      "Requirement already satisfied: scikit-learn<2 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (1.7.2)\n",
      "Requirement already satisfied: scipy<2 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (1.16.2)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (2.0.43)\n",
      "Requirement already satisfied: waitress<4 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<4 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (0.66.0)\n",
      "Requirement already satisfied: fastapi<1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (0.117.1)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (3.1.45)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (1.37.0)\n",
      "Requirement already satisfied: packaging<25 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (6.32.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (2.11.9)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (2.32.5)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (4.15.0)\n",
      "Requirement already satisfied: uvicorn<1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from mlflow-skinny==2.22.2->mlflow) (0.36.0)\n",
      "Requirement already satisfied: Mako in e:\\influence-mirror\\myenv\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: pywin32>=304 in e:\\influence-mirror\\myenv\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (311)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from Flask<4->mlflow) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from Flask<4->mlflow) (3.1.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from matplotlib<4->mlflow) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\influence-mirror\\myenv\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from matplotlib<4->mlflow) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in e:\\influence-mirror\\myenv\\lib\\site-packages (from matplotlib<4->mlflow) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from pandas!=2.3.0,<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\influence-mirror\\myenv\\lib\\site-packages (from pandas!=2.3.0,<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
      "Requirement already satisfied: colorama in e:\\influence-mirror\\myenv\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==2.22.2->mlflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth~=2.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.2->mlflow) (2.40.3)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from fastapi<1->mlflow-skinny==2.22.2->mlflow) (0.48.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.2->mlflow) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in e:\\influence-mirror\\myenv\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.2->mlflow) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.2->mlflow) (0.58b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.2->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\influence-mirror\\myenv\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.2->mlflow) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\influence-mirror\\myenv\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.2->mlflow) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in e:\\influence-mirror\\myenv\\lib\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\influence-mirror\\myenv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.2->mlflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\influence-mirror\\myenv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.2->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\influence-mirror\\myenv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.2->mlflow) (2025.8.3)\n",
      "Requirement already satisfied: h11>=0.8 in e:\\influence-mirror\\myenv\\lib\\site-packages (from uvicorn<1->mlflow-skinny==2.22.2->mlflow) (0.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.2->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.2->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\influence-mirror\\myenv\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.2->mlflow) (4.7.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in e:\\influence-mirror\\myenv\\lib\\site-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.2->mlflow) (4.10.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.2->mlflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in e:\\influence-mirror\\myenv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.2->mlflow) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5b15db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Vaibha3246\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Vaibha3246\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Vaibha3246/influence_mirror\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Vaibha3246/influence_mirror\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Vaibha3246/influence_mirror initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Vaibha3246/influence_mirror initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='Vaibha3246', repo_name='influence_mirror', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3e080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecd4389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run rogue-cow-508 at: https://dagshub.com/Vaibha3246/influence_mirror.mlflow/#/experiments/0/runs/90da48e787e64537905c2a9ed88d4aac\n",
      "üß™ View experiment at: https://dagshub.com/Vaibha3246/influence_mirror.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Vaibha3246/influence_mirror.mlflow\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\", 15)\n",
    "    mlflow.log_metric(\"metric1\", 0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6d14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('../data/raw/youtube_bulk_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2be434f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>@justicebuys1</td>\n",
       "      <td>All products can be found on www.justicebuys.c...</td>\n",
       "      <td>1978</td>\n",
       "      <td>2025-01-04T19:28:08Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>@jacklynkateisrael2568</td>\n",
       "      <td>üòÆüòÆ</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-11T09:52:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>@kevinjessica6389</td>\n",
       "      <td>Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-10T23:44:24Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>@FrancescaWhite-y6y</td>\n",
       "      <td>I was gonna say does it give you the drinks fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-09T16:25:03Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>@lucasgamingchannel-vm7pg</td>\n",
       "      <td>Anyone gonna talk abt what was o. His pc</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-08T22:33:58Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id    category                     author  \\\n",
       "0  4wZwXhoxRIA  technology              @justicebuys1   \n",
       "1  4wZwXhoxRIA  technology     @jacklynkateisrael2568   \n",
       "2  4wZwXhoxRIA  technology          @kevinjessica6389   \n",
       "3  4wZwXhoxRIA  technology        @FrancescaWhite-y6y   \n",
       "4  4wZwXhoxRIA  technology  @lucasgamingchannel-vm7pg   \n",
       "\n",
       "                                                text  likes  \\\n",
       "0  All products can be found on www.justicebuys.c...   1978   \n",
       "1                                                 üòÆüòÆ      0   \n",
       "2  Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...      0   \n",
       "3  I was gonna say does it give you the drinks fo...      0   \n",
       "4           Anyone gonna talk abt what was o. His pc      0   \n",
       "\n",
       "           published_at  \n",
       "0  2025-01-04T19:28:08Z  \n",
       "1  2025-09-11T09:52:55Z  \n",
       "2  2025-09-10T23:44:24Z  \n",
       "3  2025-09-09T16:25:03Z  \n",
       "4  2025-09-08T22:33:58Z  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7114ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id         0\n",
       "category         0\n",
       "author          10\n",
       "text            22\n",
       "likes            0\n",
       "published_at     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a045a035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76693, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3988cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='author',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de0f20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>All products can be found on www.justicebuys.c...</td>\n",
       "      <td>1978</td>\n",
       "      <td>2025-01-04T19:28:08Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>üòÆüòÆ</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-11T09:52:55Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-10T23:44:24Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>I was gonna say does it give you the drinks fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-09T16:25:03Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>Anyone gonna talk abt what was o. His pc</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-08T22:33:58Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76688</th>\n",
       "      <td>4MXqlEa6M2o</td>\n",
       "      <td>education</td>\n",
       "      <td>Ye ‡§§‡•ã ‡§¨‡•á‡§ï‡•ç‡§ï‡•Ç‡§´ ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§π‡•à</td>\n",
       "      <td>27</td>\n",
       "      <td>2025-09-09T09:31:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76689</th>\n",
       "      <td>4MXqlEa6M2o</td>\n",
       "      <td>education</td>\n",
       "      <td>Enke baat ka koi bharosa nahi hai.</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-09-09T09:30:13Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76690</th>\n",
       "      <td>4MXqlEa6M2o</td>\n",
       "      <td>education</td>\n",
       "      <td>15 September Tak 1 lakh + notification nikalo</td>\n",
       "      <td>39</td>\n",
       "      <td>2025-09-09T09:27:14Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76691</th>\n",
       "      <td>4MXqlEa6M2o</td>\n",
       "      <td>education</td>\n",
       "      <td>1st &amp; Last Education minister in Bihar</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-09-09T09:24:48Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76692</th>\n",
       "      <td>4MXqlEa6M2o</td>\n",
       "      <td>education</td>\n",
       "      <td>1.2lack boletha mantri ji</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-09T09:24:36Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76693 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id    category  \\\n",
       "0      4wZwXhoxRIA  technology   \n",
       "1      4wZwXhoxRIA  technology   \n",
       "2      4wZwXhoxRIA  technology   \n",
       "3      4wZwXhoxRIA  technology   \n",
       "4      4wZwXhoxRIA  technology   \n",
       "...            ...         ...   \n",
       "76688  4MXqlEa6M2o   education   \n",
       "76689  4MXqlEa6M2o   education   \n",
       "76690  4MXqlEa6M2o   education   \n",
       "76691  4MXqlEa6M2o   education   \n",
       "76692  4MXqlEa6M2o   education   \n",
       "\n",
       "                                                    text  likes  \\\n",
       "0      All products can be found on www.justicebuys.c...   1978   \n",
       "1                                                     üòÆüòÆ      0   \n",
       "2      Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...      0   \n",
       "3      I was gonna say does it give you the drinks fo...      0   \n",
       "4               Anyone gonna talk abt what was o. His pc      0   \n",
       "...                                                  ...    ...   \n",
       "76688                     Ye ‡§§‡•ã ‡§¨‡•á‡§ï‡•ç‡§ï‡•Ç‡§´ ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§π‡•à     27   \n",
       "76689                 Enke baat ka koi bharosa nahi hai.      4   \n",
       "76690      15 September Tak 1 lakh + notification nikalo     39   \n",
       "76691             1st & Last Education minister in Bihar      4   \n",
       "76692                          1.2lack boletha mantri ji      0   \n",
       "\n",
       "               published_at  \n",
       "0      2025-01-04T19:28:08Z  \n",
       "1      2025-09-11T09:52:55Z  \n",
       "2      2025-09-10T23:44:24Z  \n",
       "3      2025-09-09T16:25:03Z  \n",
       "4      2025-09-08T22:33:58Z  \n",
       "...                     ...  \n",
       "76688  2025-09-09T09:31:59Z  \n",
       "76689  2025-09-09T09:30:13Z  \n",
       "76690  2025-09-09T09:27:14Z  \n",
       "76691  2025-09-09T09:24:48Z  \n",
       "76692  2025-09-09T09:24:36Z  \n",
       "\n",
       "[76693 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f32be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped duplicates: 19896\n"
     ]
    }
   ],
   "source": [
    "df = df[df['text'].str.strip() != \"\"].reset_index(drop=True)\n",
    "before = len(df)\n",
    "df = df.drop_duplicates(subset=['video_id','text'], keep='first').reset_index(drop=True)\n",
    "print(\"Dropped duplicates:\", before - len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a649988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blank comments: 0\n",
      "Duplicate comments: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [video_id, category, text, likes, published_at]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Count blanks\n",
    "blank_count = (df['text'].str.strip() == \"\").sum()\n",
    "print(\"Blank comments:\", blank_count)\n",
    "\n",
    "# 2. Count duplicates\n",
    "dup_count = df.duplicated(subset=['video_id','text']).sum()\n",
    "print(\"Duplicate comments:\", dup_count)\n",
    "\n",
    "# 3. Show some examples of duplicates\n",
    "dupes = df[df.duplicated(subset=['video_id','text'], keep=False)]\n",
    "dupes.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b11daf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56797, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc00a0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in e:\\influence-mirror\\myenv\\lib\\site-packages (2.14.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c511a11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All products can be found on www.justicebuys.c...</td>\n",
       "      <td>all products can be found on üôåüèº since i review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üòÆüòÆ</td>\n",
       "      <td>üòÆüòÆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...</td>\n",
       "      <td>bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was gonna say does it give you the drinks fo...</td>\n",
       "      <td>i was gonna say does it give you the drinks fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anyone gonna talk abt what was o. His pc</td>\n",
       "      <td>anyone gonna talk abt what was o. his pc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  All products can be found on www.justicebuys.c...   \n",
       "1                                                 üòÆüòÆ   \n",
       "2  Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...   \n",
       "3  I was gonna say does it give you the drinks fo...   \n",
       "4           Anyone gonna talk abt what was o. His pc   \n",
       "\n",
       "                                          text_clean  \n",
       "0  all products can be found on üôåüèº since i review...  \n",
       "1                                                 üòÆüòÆ  \n",
       "2  bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...  \n",
       "3  i was gonna say does it give you the drinks fo...  \n",
       "4           anyone gonna talk abt what was o. his pc  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, html, emoji\n",
    "\n",
    "url_re = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "mention_re = re.compile(r'@\\w+')\n",
    "html_tag_re = re.compile(r'<.*?>')\n",
    "multispace_re = re.compile(r'\\s+')\n",
    "\n",
    "def clean_text(text, remove_emojis=False):\n",
    "    s = \"\" if pd.isna(text) else str(text)\n",
    "    s = html.unescape(s)\n",
    "    s = url_re.sub(' ', s)\n",
    "    s = mention_re.sub(' ', s)\n",
    "    s = html_tag_re.sub(' ', s)\n",
    "    if remove_emojis:\n",
    "        try:\n",
    "            s = emoji.replace_emoji(s, replace='')\n",
    "        except Exception:\n",
    "            s = s.encode('ascii', errors='ignore').decode()\n",
    "    s = s.lower().strip()\n",
    "    s = multispace_re.sub(' ', s)\n",
    "    return s\n",
    "\n",
    "df['text_clean'] = df['text'].apply(lambda x: clean_text(x, remove_emojis=False))\n",
    "df[['text','text_clean']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0de10b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>https://youtube.com/@isha-learn?si=beDQvLlqLI4...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-19T09:04:49Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>@a2d</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-01T07:07:46Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>@hopescope</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-10T03:08:56Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>ZggspAgMsyE</td>\n",
       "      <td>gaming</td>\n",
       "      <td>https://youtu.be/gaQN_xoYPtc?sub_confirmation=1</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-02T09:34:58Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>ZggspAgMsyE</td>\n",
       "      <td>gaming</td>\n",
       "      <td>https://www.youtube.com/live/e9_kRQPkryo?si=Ty...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-01T12:17:50Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52617</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>https://youtube.com/shorts/xGK0SThe9Kk?si=CcUF...</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-03T06:26:12Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53646</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>https://youtube.com/shorts/2iqLFQY7xaQ?si=GUfg...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-24T09:03:52Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53670</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>https://youtu.be/IVNYqQWjbmM?si=DlCRtfpH-1t2Vxek</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-24T04:59:47Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53713</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>https://youtube.com/shorts/Tbuet2MGwpk?si=w5od...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-23T21:32:18Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>https://youtu.be/vgvcXlUT1Vk?si=xrS-f83gqm1GbE9R</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-22T20:42:12Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>545 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id    category  \\\n",
       "232    4wZwXhoxRIA  technology   \n",
       "469    4wZwXhoxRIA  technology   \n",
       "643    4wZwXhoxRIA  technology   \n",
       "3819   ZggspAgMsyE      gaming   \n",
       "3820   ZggspAgMsyE      gaming   \n",
       "...            ...         ...   \n",
       "52617  sUf2PtEZris       music   \n",
       "53646  sUf2PtEZris       music   \n",
       "53670  sUf2PtEZris       music   \n",
       "53713  sUf2PtEZris       music   \n",
       "53936  sUf2PtEZris       music   \n",
       "\n",
       "                                                    text  likes  \\\n",
       "232    https://youtube.com/@isha-learn?si=beDQvLlqLI4...      0   \n",
       "469                                                 @a2d      0   \n",
       "643                                           @hopescope      0   \n",
       "3819     https://youtu.be/gaQN_xoYPtc?sub_confirmation=1      0   \n",
       "3820   https://www.youtube.com/live/e9_kRQPkryo?si=Ty...      0   \n",
       "...                                                  ...    ...   \n",
       "52617  https://youtube.com/shorts/xGK0SThe9Kk?si=CcUF...      2   \n",
       "53646  https://youtube.com/shorts/2iqLFQY7xaQ?si=GUfg...      1   \n",
       "53670   https://youtu.be/IVNYqQWjbmM?si=DlCRtfpH-1t2Vxek      1   \n",
       "53713  https://youtube.com/shorts/Tbuet2MGwpk?si=w5od...      0   \n",
       "53936   https://youtu.be/vgvcXlUT1Vk?si=xrS-f83gqm1GbE9R      1   \n",
       "\n",
       "               published_at text_clean  \n",
       "232    2025-05-19T09:04:49Z             \n",
       "469    2025-05-01T07:07:46Z             \n",
       "643    2025-03-10T03:08:56Z             \n",
       "3819   2025-09-02T09:34:58Z             \n",
       "3820   2025-09-01T12:17:50Z             \n",
       "...                     ...        ...  \n",
       "52617  2025-05-03T06:26:12Z             \n",
       "53646  2025-04-24T09:03:52Z             \n",
       "53670  2025-04-24T04:59:47Z             \n",
       "53713  2025-04-23T21:32:18Z             \n",
       "53936  2025-04-22T20:42:12Z             \n",
       "\n",
       "[545 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['text_clean'].str.strip() == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e109efb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56797, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5b794f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['text_clean'].str.strip() == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fa87c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>All products can be found on www.justicebuys.c...</td>\n",
       "      <td>1978</td>\n",
       "      <td>2025-01-04T19:28:08Z</td>\n",
       "      <td>all products can be found on üôåüèº since i review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>üòÆüòÆ</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-11T09:52:55Z</td>\n",
       "      <td>üòÆüòÆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-10T23:44:24Z</td>\n",
       "      <td>bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>I was gonna say does it give you the drinks fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-09T16:25:03Z</td>\n",
       "      <td>i was gonna say does it give you the drinks fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>Anyone gonna talk abt what was o. His pc</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-08T22:33:58Z</td>\n",
       "      <td>anyone gonna talk abt what was o. his pc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id    category                                               text  \\\n",
       "0  4wZwXhoxRIA  technology  All products can be found on www.justicebuys.c...   \n",
       "1  4wZwXhoxRIA  technology                                                 üòÆüòÆ   \n",
       "2  4wZwXhoxRIA  technology  Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...   \n",
       "3  4wZwXhoxRIA  technology  I was gonna say does it give you the drinks fo...   \n",
       "4  4wZwXhoxRIA  technology           Anyone gonna talk abt what was o. His pc   \n",
       "\n",
       "   likes          published_at  \\\n",
       "0   1978  2025-01-04T19:28:08Z   \n",
       "1      0  2025-09-11T09:52:55Z   \n",
       "2      0  2025-09-10T23:44:24Z   \n",
       "3      0  2025-09-09T16:25:03Z   \n",
       "4      0  2025-09-08T22:33:58Z   \n",
       "\n",
       "                                          text_clean  \n",
       "0  all products can be found on üôåüèº since i review...  \n",
       "1                                                 üòÆüòÆ  \n",
       "2  bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...  \n",
       "3  i was gonna say does it give you the drinks fo...  \n",
       "4           anyone gonna talk abt what was o. his pc  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ce88c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [video_id, category, text, likes, published_at, text_clean]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text_clean'].apply(lambda x: x.endswith(' ') or x.startswith(' '))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3abe9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trailing and leading whitespaces from the 'clean_comment' column\n",
    "df['text_clean'] = df['text_clean'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483709a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56252, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf407ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          text_clean sentiment\n",
      "0  all products can be found on üôåüèº since i review...  positive\n",
      "1                                                 üòÆüòÆ   neutral\n",
      "2  bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...   neutral\n",
      "3  i was gonna say does it give you the drinks fo...  positive\n",
      "4           anyone gonna talk abt what was o. his pc   neutral\n",
      "5  how is everyone not talking about his search?!...  positive\n",
      "6               when tech goes from wow to how?! üò≥üëâüß†  positive\n",
      "7                        this is why l love this guy  positive\n",
      "8                                    i have number 8  positive\n",
      "9  imagine using that flashlight üî¶ in the middle ...  positive\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "positive    34606\n",
      "neutral     16634\n",
      "negative     5012\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to classify sentiment\n",
    "def get_sentiment(text):\n",
    "    score = analyzer.polarity_scores(str(text))['compound']\n",
    "    if score >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "# Apply sentiment on cleaned text\n",
    "df['sentiment'] = df['text_clean'].apply(get_sentiment)\n",
    "\n",
    "# Check results\n",
    "print(df[['text_clean', 'sentiment']].head(10))\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2d3d71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20837</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>29 july 2025 ko kon kon dekh rahe ho,,??</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-07-28T20:01:18Z</td>\n",
       "      <td>29 july 2025 ko kon kon dekh rahe ho,,??</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34185</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>How many of you listen at least one time per d...</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-06-25T14:48:55Z</td>\n",
       "      <td>how many of you listen at least one time per d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7674</th>\n",
       "      <td>iFIbm4Xqjwo</td>\n",
       "      <td>movies</td>\n",
       "      <td>Bro is swinging like a complete üê±</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-26T17:02:14Z</td>\n",
       "      <td>bro is swinging like a complete üê±</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25968</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>I am here after laughter chef üòÇ</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-07-14T16:19:12Z</td>\n",
       "      <td>i am here after laughter chef üòÇ</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49658</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>Viral in Nepal üî•</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-21T12:08:00Z</td>\n",
       "      <td>viral in nepal üî•</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53179</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>Global level video quality and concept and son...</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-27T06:57:51Z</td>\n",
       "      <td>global level video quality and concept and son...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21503</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>27 July ko kon kon sun rha h?</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-26T16:54:22Z</td>\n",
       "      <td>27 july ko kon kon sun rha h?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>vwTL0SLEl1M</td>\n",
       "      <td>technology</td>\n",
       "      <td>i'm still using HDMI, and my monitor only supp...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-08-26T05:34:47Z</td>\n",
       "      <td>i'm still using hdmi, and my monitor only supp...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>nice try diddy</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-05T07:57:16Z</td>\n",
       "      <td>nice try diddy</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55214</th>\n",
       "      <td>o-YjuXcZ9l8</td>\n",
       "      <td>education</td>\n",
       "      <td>Please sir üôè</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-11T14:19:16Z</td>\n",
       "      <td>please sir üôè</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id    category  \\\n",
       "20837  sUf2PtEZris       music   \n",
       "34185  sUf2PtEZris       music   \n",
       "7674   iFIbm4Xqjwo      movies   \n",
       "25968  sUf2PtEZris       music   \n",
       "49658  sUf2PtEZris       music   \n",
       "53179  sUf2PtEZris       music   \n",
       "21503  sUf2PtEZris       music   \n",
       "3034   vwTL0SLEl1M  technology   \n",
       "1937   4wZwXhoxRIA  technology   \n",
       "55214  o-YjuXcZ9l8   education   \n",
       "\n",
       "                                                    text  likes  \\\n",
       "20837           29 july 2025 ko kon kon dekh rahe ho,,??      4   \n",
       "34185  How many of you listen at least one time per d...      3   \n",
       "7674                   Bro is swinging like a complete üê±      0   \n",
       "25968                    I am here after laughter chef üòÇ      3   \n",
       "49658                                   Viral in Nepal üî•      0   \n",
       "53179  Global level video quality and concept and son...      3   \n",
       "21503                      27 July ko kon kon sun rha h?      0   \n",
       "3034   i'm still using HDMI, and my monitor only supp...      0   \n",
       "1937                                      nice try diddy      1   \n",
       "55214                                       Please sir üôè      0   \n",
       "\n",
       "               published_at  \\\n",
       "20837  2025-07-28T20:01:18Z   \n",
       "34185  2025-06-25T14:48:55Z   \n",
       "7674   2025-07-26T17:02:14Z   \n",
       "25968  2025-07-14T16:19:12Z   \n",
       "49658  2025-05-21T12:08:00Z   \n",
       "53179  2025-04-27T06:57:51Z   \n",
       "21503  2025-07-26T16:54:22Z   \n",
       "3034   2025-08-26T05:34:47Z   \n",
       "1937   2025-01-05T07:57:16Z   \n",
       "55214  2025-09-11T14:19:16Z   \n",
       "\n",
       "                                              text_clean sentiment  \n",
       "20837           29 july 2025 ko kon kon dekh rahe ho,,??   neutral  \n",
       "34185  how many of you listen at least one time per d...  positive  \n",
       "7674                   bro is swinging like a complete üê±  positive  \n",
       "25968                    i am here after laughter chef üòÇ  positive  \n",
       "49658                                   viral in nepal üî•  negative  \n",
       "53179  global level video quality and concept and son...  positive  \n",
       "21503                      27 july ko kon kon sun rha h?   neutral  \n",
       "3034   i'm still using hdmi, and my monitor only supp...  positive  \n",
       "1937                                      nice try diddy  positive  \n",
       "55214                                       please sir üôè  positive  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e573d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean']=df['text_clean'].str.replace('\\n', ' ', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "524f1f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaibh\\AppData\\Local\\Temp\\ipykernel_6740\\1706387719.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sentiment_numeric'] = df['sentiment'].replace({\n"
     ]
    }
   ],
   "source": [
    "df['sentiment_numeric'] = df['sentiment'].replace({\n",
    "    'positive': 1,\n",
    "    'negative': -1,\n",
    "    'neutral': 0\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04a7528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count']=df['text_clean'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a499391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>vwTL0SLEl1M</td>\n",
       "      <td>technology</td>\n",
       "      <td>Please convince my dad that he will let me buy...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-08-26T13:26:46Z</td>\n",
       "      <td>please convince my dad that he will let me buy...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id    category  \\\n",
       "2786  vwTL0SLEl1M  technology   \n",
       "\n",
       "                                                   text  likes  \\\n",
       "2786  Please convince my dad that he will let me buy...      0   \n",
       "\n",
       "              published_at                                         text_clean  \\\n",
       "2786  2025-08-26T13:26:46Z  please convince my dad that he will let me buy...   \n",
       "\n",
       "     sentiment  sentiment_numeric  word_count  \n",
       "2786  positive                  1          27  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a29058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         word  frequency\n",
      "15159    song       8056\n",
      "9424      kon       7176\n",
      "40        the       6545\n",
      "8           i       4614\n",
      "30         is       4565\n",
      "24         to       4010\n",
      "8814      hai       3978\n",
      "14          a       3748\n",
      "69       this       3602\n",
      "125       and       3502\n",
      "39        you       3085\n",
      "8890       ko       2820\n",
      "44     anyone       2695\n",
      "27         in       2640\n",
      "9323     dekh       2525\n",
      "757         ‚ù§       2493\n",
      "85       like       2484\n",
      "37         it       2443\n",
      "8987     raha       2439\n",
      "82         of       2420\n"
     ]
    }
   ],
   "source": [
    "# Word frequency ‚Üí shows most common terms used (good for making word clouds,\n",
    "# stopwords analysis).\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Combine all comments into one large string\n",
    "all_text = ' '.join(df['text_clean'])\n",
    "\n",
    "# Split into words and count\n",
    "word_frequency = Counter(all_text.split())\n",
    "\n",
    "# Convert into DataFrame\n",
    "word_frequency_df = pd.DataFrame(word_frequency.items(), columns=['word', 'frequency']).sort_values(by='frequency', ascending=False)\n",
    "\n",
    "print(word_frequency_df.head(20))  # top 20 words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "147edd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in e:\\influence-mirror\\myenv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in e:\\influence-mirror\\myenv\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in e:\\influence-mirror\\myenv\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\influence-mirror\\myenv\\lib\\site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in e:\\influence-mirror\\myenv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in e:\\influence-mirror\\myenv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a421755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['word_count'] >= 2) & (df['word_count'] <= 100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59f77101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vaibh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stopwords if not already downloaded\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define the list of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Create a new column 'num_stop_words' by counting the number of stopwords in each comment\n",
    "df['num_stop_words'] = df['text_clean'].apply(lambda x: len([word for word in x.split() if word in stop_words]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fea804da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>word_count</th>\n",
       "      <th>num_stop_words</th>\n",
       "      <th>num_punctuation_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8617</th>\n",
       "      <td>GJZAcj4P99g</td>\n",
       "      <td>music</td>\n",
       "      <td>Happy Onam üéâ‚ù§‚ù§‚ù§üéâüéâ</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-05T16:44:10Z</td>\n",
       "      <td>happy onam üéâ‚ù§‚ù§‚ù§üéâüéâ</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51786</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>Ek number lots of love from goa</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-05-07T22:23:40Z</td>\n",
       "      <td>ek number lots of love from goa</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15650</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>The right and left girl is like a ghostüòÇüòÇüòÇüòÇ bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-08-18T09:40:05Z</td>\n",
       "      <td>the right and left girl is like a ghostüòÇüòÇüòÇüòÇ bu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>vwTL0SLEl1M</td>\n",
       "      <td>technology</td>\n",
       "      <td>will it be a consumer product tho?</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-08-26T03:05:25Z</td>\n",
       "      <td>will it be a consumer product tho?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53362</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>Lavkar ch Trending la ü•∞ü•∞</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-26T04:43:29Z</td>\n",
       "      <td>lavkar ch trending la ü•∞ü•∞</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id    category  \\\n",
       "8617   GJZAcj4P99g       music   \n",
       "51786  sUf2PtEZris       music   \n",
       "15650  sUf2PtEZris       music   \n",
       "3105   vwTL0SLEl1M  technology   \n",
       "53362  sUf2PtEZris       music   \n",
       "\n",
       "                                                    text  likes  \\\n",
       "8617                                   Happy Onam üéâ‚ù§‚ù§‚ù§üéâüéâ      0   \n",
       "51786                    Ek number lots of love from goa      4   \n",
       "15650  The right and left girl is like a ghostüòÇüòÇüòÇüòÇ bu...      0   \n",
       "3105                  will it be a consumer product tho?      0   \n",
       "53362                           Lavkar ch Trending la ü•∞ü•∞      1   \n",
       "\n",
       "               published_at  \\\n",
       "8617   2025-09-05T16:44:10Z   \n",
       "51786  2025-05-07T22:23:40Z   \n",
       "15650  2025-08-18T09:40:05Z   \n",
       "3105   2025-08-26T03:05:25Z   \n",
       "53362  2025-04-26T04:43:29Z   \n",
       "\n",
       "                                              text_clean sentiment  \\\n",
       "8617                                   happy onam üéâ‚ù§‚ù§‚ù§üéâüéâ  positive   \n",
       "51786                    ek number lots of love from goa  positive   \n",
       "15650  the right and left girl is like a ghostüòÇüòÇüòÇüòÇ bu...  positive   \n",
       "3105                  will it be a consumer product tho?   neutral   \n",
       "53362                           lavkar ch trending la ü•∞ü•∞  positive   \n",
       "\n",
       "       sentiment_numeric  word_count  num_stop_words  num_punctuation_chars  \n",
       "8617                   1           3               0                      0  \n",
       "51786                  1           7               2                      0  \n",
       "15650                  1          20               9                      0  \n",
       "3105                   0           7               4                      1  \n",
       "53362                  1           5               0                      0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'num_punctuation_chars' to count punctuation characters in each comment\n",
    "df['num_punctuation_chars'] = df['text_clean'].apply(\n",
    "    lambda x: sum([1 for char in x if char in '.,!?;:\"\\'()[]{}-'])\n",
    ")\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9517e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>word_count</th>\n",
       "      <th>num_stop_words</th>\n",
       "      <th>num_punctuation_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46251</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>Never imagined such song... Wow‚ù§‚ù§‚ù§‚ù§so addictive</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-01T17:02:33Z</td>\n",
       "      <td>never imagined such song... wow‚ù§‚ù§‚ù§‚ù§so addictive</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20194</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>Best.  Song.      Sanju.       Bhai</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-31T08:15:10Z</td>\n",
       "      <td>best. song. sanju. bhai</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20187</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>31 ko kon kon dek rehai ho üòÖüòÖüòÖüòÇ</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-31T09:05:56Z</td>\n",
       "      <td>31 ko kon kon dek rehai ho üòÖüòÖüòÖüòÇ</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20829</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>Sindhi + English</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-28T23:06:30Z</td>\n",
       "      <td>sindhi + english</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27786</th>\n",
       "      <td>sUf2PtEZris</td>\n",
       "      <td>music</td>\n",
       "      <td>So nice song!!‚ù§‚ù§‚ù§</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-10T09:16:39Z</td>\n",
       "      <td>so nice song!!‚ù§‚ù§‚ù§</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id category                                             text  \\\n",
       "46251  sUf2PtEZris    music  Never imagined such song... Wow‚ù§‚ù§‚ù§‚ù§so addictive   \n",
       "20194  sUf2PtEZris    music              Best.  Song.      Sanju.       Bhai   \n",
       "20187  sUf2PtEZris    music                  31 ko kon kon dek rehai ho üòÖüòÖüòÖüòÇ   \n",
       "20829  sUf2PtEZris    music                                 Sindhi + English   \n",
       "27786  sUf2PtEZris    music                                So nice song!!‚ù§‚ù§‚ù§   \n",
       "\n",
       "       likes          published_at  \\\n",
       "46251      1  2025-06-01T17:02:33Z   \n",
       "20194      0  2025-07-31T08:15:10Z   \n",
       "20187      0  2025-07-31T09:05:56Z   \n",
       "20829      0  2025-07-28T23:06:30Z   \n",
       "27786      0  2025-07-10T09:16:39Z   \n",
       "\n",
       "                                            text_clean sentiment  \\\n",
       "46251  never imagined such song... wow‚ù§‚ù§‚ù§‚ù§so addictive  positive   \n",
       "20194                          best. song. sanju. bhai  positive   \n",
       "20187                  31 ko kon kon dek rehai ho üòÖüòÖüòÖüòÇ  positive   \n",
       "20829                                 sindhi + english   neutral   \n",
       "27786                                so nice song!!‚ù§‚ù§‚ù§  positive   \n",
       "\n",
       "       sentiment_numeric  word_count  num_stop_words  num_punctuation_chars  \n",
       "46251                  1           6               1                      3  \n",
       "20194                  1           4               0                      3  \n",
       "20187                  1           8               0                      0  \n",
       "20829                  0           3               0                      0  \n",
       "27786                  1           3               1                      2  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e184a769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>word_count</th>\n",
       "      <th>num_stop_words</th>\n",
       "      <th>num_punctuation_chars</th>\n",
       "      <th>num_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>All products can be found on www.justicebuys.c...</td>\n",
       "      <td>1978</td>\n",
       "      <td>2025-01-04T19:28:08Z</td>\n",
       "      <td>all products can be found on üôåüèº since i review...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-10T23:44:24Z</td>\n",
       "      <td>bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>I was gonna say does it give you the drinks fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-09T16:25:03Z</td>\n",
       "      <td>i was gonna say does it give you the drinks fo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>Anyone gonna talk abt what was o. His pc</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-08T22:33:58Z</td>\n",
       "      <td>anyone gonna talk abt what was o. his pc</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>HOW IS EVERYONE NOT TALKING ABOUT HIS SEARCH?!...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-08T12:17:37Z</td>\n",
       "      <td>how is everyone not talking about his search?!...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id    category                                               text  \\\n",
       "0  4wZwXhoxRIA  technology  All products can be found on www.justicebuys.c...   \n",
       "2  4wZwXhoxRIA  technology  Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...   \n",
       "3  4wZwXhoxRIA  technology  I was gonna say does it give you the drinks fo...   \n",
       "4  4wZwXhoxRIA  technology           Anyone gonna talk abt what was o. His pc   \n",
       "5  4wZwXhoxRIA  technology  HOW IS EVERYONE NOT TALKING ABOUT HIS SEARCH?!...   \n",
       "\n",
       "   likes          published_at  \\\n",
       "0   1978  2025-01-04T19:28:08Z   \n",
       "2      0  2025-09-10T23:44:24Z   \n",
       "3      0  2025-09-09T16:25:03Z   \n",
       "4      0  2025-09-08T22:33:58Z   \n",
       "5      0  2025-09-08T12:17:37Z   \n",
       "\n",
       "                                          text_clean sentiment  \\\n",
       "0  all products can be found on üôåüèº since i review...  positive   \n",
       "2  bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...   neutral   \n",
       "3  i was gonna say does it give you the drinks fo...  positive   \n",
       "4           anyone gonna talk abt what was o. his pc   neutral   \n",
       "5  how is everyone not talking about his search?!...  positive   \n",
       "\n",
       "   sentiment_numeric  word_count  num_stop_words  num_punctuation_chars  \\\n",
       "0                  1          24               9                      1   \n",
       "2                  0          12               5                      0   \n",
       "3                  1          12               7                      1   \n",
       "4                  0           9               3                      1   \n",
       "5                  1          15               6                      4   \n",
       "\n",
       "   num_chars  \n",
       "0        116  \n",
       "2         53  \n",
       "3         54  \n",
       "4         40  \n",
       "5         85  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['num_chars'] = df['text_clean'].apply(len)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "004bccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vaibh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>word_count</th>\n",
       "      <th>num_stop_words</th>\n",
       "      <th>num_punctuation_chars</th>\n",
       "      <th>num_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>All products can be found on www.justicebuys.c...</td>\n",
       "      <td>1978</td>\n",
       "      <td>2025-01-04T19:28:08Z</td>\n",
       "      <td>all product can be found on üôåüèº since i review ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-10T23:44:24Z</td>\n",
       "      <td>bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>I was gonna say does it give you the drinks fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-09T16:25:03Z</td>\n",
       "      <td>i wa gonna say doe it give you the drink for f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>Anyone gonna talk abt what was o. His pc</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-08T22:33:58Z</td>\n",
       "      <td>anyone gonna talk abt what wa o. his pc</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>HOW IS EVERYONE NOT TALKING ABOUT HIS SEARCH?!...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-08T12:17:37Z</td>\n",
       "      <td>how is everyone not talking about his search?!...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id    category                                               text  \\\n",
       "0  4wZwXhoxRIA  technology  All products can be found on www.justicebuys.c...   \n",
       "2  4wZwXhoxRIA  technology  Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...   \n",
       "3  4wZwXhoxRIA  technology  I was gonna say does it give you the drinks fo...   \n",
       "4  4wZwXhoxRIA  technology           Anyone gonna talk abt what was o. His pc   \n",
       "5  4wZwXhoxRIA  technology  HOW IS EVERYONE NOT TALKING ABOUT HIS SEARCH?!...   \n",
       "\n",
       "   likes          published_at  \\\n",
       "0   1978  2025-01-04T19:28:08Z   \n",
       "2      0  2025-09-10T23:44:24Z   \n",
       "3      0  2025-09-09T16:25:03Z   \n",
       "4      0  2025-09-08T22:33:58Z   \n",
       "5      0  2025-09-08T12:17:37Z   \n",
       "\n",
       "                                          text_clean sentiment  \\\n",
       "0  all product can be found on üôåüèº since i review ...  positive   \n",
       "2  bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...   neutral   \n",
       "3  i wa gonna say doe it give you the drink for f...  positive   \n",
       "4            anyone gonna talk abt what wa o. his pc   neutral   \n",
       "5  how is everyone not talking about his search?!...  positive   \n",
       "\n",
       "   sentiment_numeric  word_count  num_stop_words  num_punctuation_chars  \\\n",
       "0                  1          24               9                      1   \n",
       "2                  0          12               5                      0   \n",
       "3                  1          12               7                      1   \n",
       "4                  0           9               3                      1   \n",
       "5                  1          15               6                      4   \n",
       "\n",
       "   num_chars  \n",
       "0        116  \n",
       "2         53  \n",
       "3         54  \n",
       "4         40  \n",
       "5         85  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apply lemmatization to the 'clean_comment_no_stopwords' column\n",
    "df['text_clean'] = df['text_clean'].apply(\n",
    "    lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()])\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dad52d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "df['hour'] = df['published_at'].dt.hour\n",
    "df['weekday'] = df['published_at'].dt.weekday\n",
    "df['month'] = df['published_at'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e492edc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>published_at</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>word_count</th>\n",
       "      <th>num_stop_words</th>\n",
       "      <th>num_punctuation_chars</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>category_gaming</th>\n",
       "      <th>category_movies</th>\n",
       "      <th>category_music</th>\n",
       "      <th>category_technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>All products can be found on www.justicebuys.c...</td>\n",
       "      <td>1978</td>\n",
       "      <td>2025-01-04 19:28:08+00:00</td>\n",
       "      <td>all product can be found on üôåüèº since i review ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-10 23:44:24+00:00</td>\n",
       "      <td>bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>I was gonna say does it give you the drinks fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-09 16:25:03+00:00</td>\n",
       "      <td>i wa gonna say doe it give you the drink for f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>Anyone gonna talk abt what was o. His pc</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-08 22:33:58+00:00</td>\n",
       "      <td>anyone gonna talk abt what wa o. his pc</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4wZwXhoxRIA</td>\n",
       "      <td>technology</td>\n",
       "      <td>HOW IS EVERYONE NOT TALKING ABOUT HIS SEARCH?!...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-08 12:17:37+00:00</td>\n",
       "      <td>how is everyone not talking about his search?!...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id    category                                               text  \\\n",
       "0  4wZwXhoxRIA  technology  All products can be found on www.justicebuys.c...   \n",
       "1  4wZwXhoxRIA  technology  Bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...   \n",
       "2  4wZwXhoxRIA  technology  I was gonna say does it give you the drinks fo...   \n",
       "3  4wZwXhoxRIA  technology           Anyone gonna talk abt what was o. His pc   \n",
       "4  4wZwXhoxRIA  technology  HOW IS EVERYONE NOT TALKING ABOUT HIS SEARCH?!...   \n",
       "\n",
       "   likes              published_at  \\\n",
       "0   1978 2025-01-04 19:28:08+00:00   \n",
       "1      0 2025-09-10 23:44:24+00:00   \n",
       "2      0 2025-09-09 16:25:03+00:00   \n",
       "3      0 2025-09-08 22:33:58+00:00   \n",
       "4      0 2025-09-08 12:17:37+00:00   \n",
       "\n",
       "                                          text_clean sentiment  \\\n",
       "0  all product can be found on üôåüèº since i review ...  positive   \n",
       "1  bro ‚Äúhow to talk to woman in 6 steps‚Äù is so re...   neutral   \n",
       "2  i wa gonna say doe it give you the drink for f...  positive   \n",
       "3            anyone gonna talk abt what wa o. his pc   neutral   \n",
       "4  how is everyone not talking about his search?!...  positive   \n",
       "\n",
       "   sentiment_numeric  word_count  num_stop_words  num_punctuation_chars  \\\n",
       "0                  1          24               9                      1   \n",
       "1                  0          12               5                      0   \n",
       "2                  1          12               7                      1   \n",
       "3                  0           9               3                      1   \n",
       "4                  1          15               6                      4   \n",
       "\n",
       "   num_chars  hour  weekday  month  category_gaming  category_movies  \\\n",
       "0        116    19        5      1              0.0              0.0   \n",
       "1         53    23        2      9              0.0              0.0   \n",
       "2         54    16        1      9              0.0              0.0   \n",
       "3         40    22        0      9              0.0              0.0   \n",
       "4         85    12        0      9              0.0              0.0   \n",
       "\n",
       "   category_music  category_technology  \n",
       "0             0.0                  1.0  \n",
       "1             0.0                  1.0  \n",
       "2             0.0                  1.0  \n",
       "3             0.0                  1.0  \n",
       "4             0.0                  1.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# ‚úÖ Handle both sklearn versions\n",
    "try:\n",
    "    ohe = OneHotEncoder(sparse_output=False, drop=\"first\")  # new versions\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(sparse=False, drop=\"first\")  # older versions\n",
    "\n",
    "category_encoded = ohe.fit_transform(df[['category']])\n",
    "\n",
    "# Convert back to DataFrame with category names\n",
    "category_df = pd.DataFrame(category_encoded, columns=ohe.get_feature_names_out(['category']))\n",
    "\n",
    "# Merge into original DataFrame\n",
    "df = pd.concat([df.reset_index(drop=True), category_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9295d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\vaibh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#  Add VADER Sentiment Scores\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "df[['sent_neg', 'sent_neu', 'sent_pos', 'sent_compound']] = df['text_clean'].apply(\n",
    "    lambda x: pd.Series(sia.polarity_scores(x))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778ef5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90437591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3109d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numeric columns\n",
    "X = df.drop(columns=['video_id','category','text','text_clean','sentiment','published_at','sentiment_numeric'])\n",
    "y = df['sentiment_numeric']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "020f093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9761ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup mlflow tracking server\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Vaibha3246/influence_mirror.mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a20f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/26 11:27:44 INFO mlflow.tracking.fluent: Experiment with name 'RF Baseline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/008c5a930fca452a8fa9d2ef4f21e105', creation_time=1758866263515, experiment_id='0', last_update_time=1758866263515, lifecycle_stage='active', name='RF Baseline', tags={}>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set or create an experiment\n",
    "mlflow.set_experiment(\"RF Baseline\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f916edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/26 11:29:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run RandomForest_Baseline_TrainTestSplit at: https://dagshub.com/Vaibha3246/influence_mirror.mlflow/#/experiments/0/runs/0900e0a7b0484667a31580faf09d4e24\n",
      "üß™ View experiment at: https://dagshub.com/Vaibha3246/influence_mirror.mlflow/#/experiments/0\n",
      "‚úÖ Accuracy: 0.7269\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Step 0: Import required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train/test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ‚úÖ Step 2: Define and train  a Random Forest baseline model using MLflow\n",
    "with mlflow.start_run() as run:\n",
    "    # --- MLflow Run Tags ---\n",
    "    mlflow.set_tag(\"mlflow.runName\", \"RandomForest_Baseline_TrainTestSplit\")\n",
    "    mlflow.set_tag(\"experiment_type\", \"baseline\")\n",
    "    mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
    "    mlflow.set_tag(\n",
    "        \"description\",\n",
    "        \"Baseline RandomForest model for sentiment analysis  with a simple train-test split\",\n",
    "    )\n",
    "\n",
    "    # --- Model Parameters ---\n",
    "    n_estimators = 200\n",
    "    max_depth = 15\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "\n",
    "    # --- Train Model ---\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, max_depth=max_depth, random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- Predictions ---\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # --- Metrics ---\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "    for label, metrics in classification_rep.items():\n",
    "        if isinstance(metrics, dict):  # Only log precision, recall, f1-score\n",
    "            for metric, value in metrics.items():\n",
    "                mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "    # --- Confusion Matrix ---\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "\n",
    "    # Save and log confusion matrix plot\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # --- Log Model ---\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
    "\n",
    "    # --- Optionally Log Dataset (if small) ---\n",
    "    # Example: if you have your DataFrame as df\n",
    "    df.to_csv(\"dataset.csv\", index=False)\n",
    "    mlflow.log_artifact(\"dataset.csv\")\n",
    "\n",
    "# ‚úÖ Print Final Accuracy\n",
    "print(f\"‚úÖ Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26068cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e4fa115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.63      0.70       938\n",
      "           0       0.65      0.42      0.51      2875\n",
      "           1       0.74      0.89      0.81      6094\n",
      "\n",
      "    accuracy                           0.73      9907\n",
      "   macro avg       0.73      0.65      0.67      9907\n",
      "weighted avg       0.72      0.73      0.71      9907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2287a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('reddit_preprocessing.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
